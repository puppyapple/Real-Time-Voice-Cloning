{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveRNN - Fit a 30min Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys, math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import wavfile\n",
    "from utils.display import *\n",
    "from utils.dsp import *\n",
    "from models.wavernn import WaveRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = 'nb3'\n",
    "sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = wavfile.read('data/podcast.wav')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.min(), sample.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split/Combine Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_signal(x) :\n",
    "    unsigned = x + 2**15\n",
    "    coarse = unsigned // 256\n",
    "    fine = unsigned % 256\n",
    "    return coarse, fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_signal(coarse, fine) :\n",
    "    return coarse * 256 + fine - 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sample[73000:73100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_classes, fine_classes = split_signal(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(coarse_classes[73000:73100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(fine_classes[73000:73100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveRNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_classes, fine_classes = split_signal(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # 8gb gpu\n",
    "coarse_classes = coarse_classes[:len(coarse_classes) // batch_size * batch_size]\n",
    "fine_classes = fine_classes[:len(fine_classes) // batch_size * batch_size]\n",
    "coarse_classes = np.reshape(coarse_classes, (batch_size, -1))\n",
    "fine_classes = np.reshape(fine_classes, (batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_steps, batch_size, lr=1e-3, seq_len=960) :\n",
    "    \n",
    "    for p in optimizer.param_groups : p['lr'] = lr\n",
    "    start = time.time()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for step in range(num_steps) :\n",
    "        \n",
    "        loss = 0\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        rand_idx = np.random.randint(0, coarse_classes.shape[1] - seq_len - 1)\n",
    "        \n",
    "        x_coarse = coarse_classes[:, rand_idx:rand_idx + seq_len]\n",
    "        x_coarse = torch.FloatTensor(x_coarse)\n",
    "        x_coarse = x_coarse / 127.5 - 1.\n",
    "        x_fine = fine_classes[:, rand_idx:rand_idx + seq_len]\n",
    "        x_fine = torch.FloatTensor(x_fine)\n",
    "        x_fine = x_fine / 127.5 - 1.\n",
    "        \n",
    "        y_coarse = coarse_classes[:, rand_idx + 1:rand_idx + seq_len + 1]\n",
    "        y_coarse = torch.LongTensor(y_coarse)\n",
    "        y_fine = fine_classes[:, rand_idx + 1: rand_idx + seq_len + 1]\n",
    "        y_fine = torch.LongTensor(y_fine)\n",
    "        \n",
    "        for i in range(seq_len) :\n",
    "            \n",
    "            x_c_in = x_coarse[:, i:i + 1]\n",
    "            x_f_in = x_fine[:, i:i + 1]\n",
    "            x_input = torch.cat([x_c_in, x_f_in], dim=1)\n",
    "            x_input = x_input.cuda()\n",
    "            \n",
    "            c_target = y_coarse[:, i].cuda()\n",
    "            f_target = y_fine[:, i].cuda()\n",
    "            \n",
    "            \n",
    "            current_coarse = c_target.float() / 127.5 - 1.\n",
    "            current_coarse = current_coarse.unsqueeze(-1)\n",
    "            \n",
    "            out_coarse, out_fine, hidden = model(x_input, hidden, current_coarse)\n",
    "            \n",
    "            loss_coarse = F.cross_entropy(out_coarse, c_target)\n",
    "            loss_fine = F.cross_entropy(out_fine, f_target)\n",
    "            loss += (loss_coarse + loss_fine)\n",
    "        \n",
    "        running_loss += (loss.item() / seq_len)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        elapsed = time_since(start)\n",
    "        speed = (step + 1) / (time.time() - start)\n",
    "        \n",
    "        stream('Step: %i/%i --- Loss: %.3f --- %s --- @ %.1f batches/sec ',\n",
    "              (step + 1, num_steps, running_loss / (step + 1), elapsed, speed))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, num_steps=10000, batch_size=batch_size, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output, c, f = model.generate(sample_rate * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(output[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(f[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wav(y, filename, sample_rate) :\n",
    "    y = np.clip(y, -2**15, 2**15 - 1)\n",
    "    wavfile.write(filename, sample_rate, y.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_wav(output, f'outputs/{notebook_name}/model_output.wav', sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
