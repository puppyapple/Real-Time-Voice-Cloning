{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveRNN - Fit a Short Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time, sys, math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import wavfile\n",
    "from utils.display import *\n",
    "from utils.dsp import *\n",
    "from models.wavernn import WaveRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = 'nb2'\n",
    "sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = wavfile.read('data/female_vocal_op8_8.wav')[1]\n",
    "coarse_classes, fine_classes = split_signal(sample)\n",
    "\n",
    "plot(coarse_classes[3000:3100])\n",
    "plot(fine_classes[3000:3100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveRNN().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_classes, fine_classes = split_signal(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "coarse_classes = coarse_classes[:len(coarse_classes) // batch_size * batch_size]\n",
    "fine_classes = fine_classes[:len(fine_classes) // batch_size * batch_size]\n",
    "coarse_classes = np.reshape(coarse_classes, (batch_size, -1))\n",
    "fine_classes = np.reshape(fine_classes, (batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, num_steps, batch_size, seq_len=960) :\n",
    "    \n",
    "    start = time.time()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for step in range(num_steps) :\n",
    "        \n",
    "        loss = 0\n",
    "        hidden = model.init_hidden(batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        rand_idx = np.random.randint(0, coarse_classes.shape[1] - seq_len - 1)\n",
    "        \n",
    "        for i in range(seq_len) :\n",
    "            \n",
    "            j = rand_idx + i\n",
    "            \n",
    "            x_coarse = coarse_classes[:, j:j + 1]\n",
    "            x_fine = fine_classes[:, j:j + 1]\n",
    "            x_input = np.concatenate([x_coarse, x_fine], axis=1)\n",
    "            x_input = x_input / 127.5 - 1.\n",
    "            x_input = torch.FloatTensor(x_input).cuda()\n",
    "            \n",
    "            y_coarse = coarse_classes[:, j + 1]\n",
    "            y_fine = fine_classes[:, j + 1]\n",
    "            y_coarse = torch.LongTensor(y_coarse).cuda()\n",
    "            y_fine = torch.LongTensor(y_fine).cuda()\n",
    "            \n",
    "            current_coarse = y_coarse.float() / 127.5 - 1.\n",
    "            current_coarse = current_coarse.unsqueeze(-1)\n",
    "            \n",
    "            out_coarse, out_fine, hidden = model(x_input, hidden, current_coarse)\n",
    "            \n",
    "            loss_coarse = F.cross_entropy(out_coarse, y_coarse)\n",
    "            loss_fine = F.cross_entropy(out_fine, y_fine)\n",
    "            loss += (loss_coarse + loss_fine)\n",
    "        \n",
    "        running_loss += (loss.item() / seq_len)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        speed = (step + 1) / (time.time() - start)\n",
    "        \n",
    "        stream('Step: %i/%i --- Loss: %.2f --- Speed: %.1f batches/second ',\n",
    "              (step + 1, num_steps, running_loss / (step + 1), speed))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, num_steps=1000, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output, c, f = model.generate(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(output[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(f[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wav(y, filename, sample_rate) :\n",
    "    y = np.clip(y, -2**15, 2**15 - 1)\n",
    "    wavfile.write(filename, sample_rate, y.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_wav(output, f'outputs/{notebook_name}/1k_steps.wav', sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
